{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize data \n",
    "# Download dataset \n",
    "# dat dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \n",
    "TRAIN_DATA_DIR = 'train/'\n",
    "VALIDATION_DATA_DIR = 'val/'\n",
    "TRAIN_SAMPLES = 500\n",
    "VALIDATION_SAMPLES = 500\n",
    "NUM_CLASSES = 2\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and augment the data \n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   zoom_range=0.2)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train generator\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_DATA_DIR,\n",
    "                                                    target_size=(IMG_WIDTH,\n",
    "                                                                 IMG_HEIGHT),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=12345,\n",
    "                                                    class_mode='categorical')\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model \n",
    "def model_maker():\n",
    "    base_model = MobileNet(include_top=False,\n",
    "                           input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    custom_model = base_model(input)\n",
    "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
    "    custom_model = Dense(64, activation='relu')(custom_model)\n",
    "    custom_model = Dropout(0.5)(custom_model)\n",
    "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
    "    return Model(inputs=input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_maker()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              metrics=['acc'])\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=math.ceil(float(TRAIN_SAMPLES) / BATCH_SIZE),\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=math.ceil(float(VALIDATION_SAMPLES) / BATCH_SIZE))\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "model = load_model('model.h5')\n",
    "\n",
    "img_path = 'https://i.imgur.com/7mK8VHe.png'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "preprocessed_img = expanded_img_array / 255.  # Preprocess the image\n",
    "prediction = model.predict(preprocessed_img)\n",
    "print(prediction)\n",
    "print(validation_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and data \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pipeline confg\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "VALIDATION_DATA_DIR = 'data/val/'\n",
    "VALIDATION_BATCH_SIZE = 64\n",
    "\n",
    "# Read data \n",
    "\n",
    "\n",
    "# Augment data \n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=VALIDATION_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "\n",
    "with CustomObjectScope(\n",
    "    {'GlorotUniform': glorot_uniform()}):\n",
    "    model = load_model('data/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of files in folder \n",
    "filenames = validation_generator.filenames\n",
    "print(len(filenames))\n",
    "print(filenames[:10])\n",
    "\n",
    "ground_truth = validation_generator.classes\n",
    "print(ground_truth[:10])\n",
    "print(len(ground_truth))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_index = validation_generator.class_indices\n",
    "print(label_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_label = dict((v, k) for k, v in label_to_index.items())\n",
    "print(index_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction\n",
    "predictions = model.predict_generator(validation_generator,\n",
    "                                      steps=None)\n",
    "\n",
    "print(predictions[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index = []\n",
    "for prediction in predictions:\n",
    "    prediction_index.append(np.argmax(prediction))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, ground_truth):\n",
    "    total = 0\n",
    "    for i, j in zip(predictions, ground_truth):\n",
    "        if i == j:\n",
    "            total += 1\n",
    "    return total * 1.0 / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy(prediction_index, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_table = {}\n",
    "for index, val in enumerate(predictions):\n",
    "    index_of_highest_probability = np.argmax(val)\n",
    "    value_of_highest_probability = val[index_of_highest_probability]\n",
    "    prediction_table[index] = [\n",
    "        value_of_highest_probability, index_of_highest_probability,\n",
    "        ground_truth[index]\n",
    "    ]\n",
    "assert len(predictions) == len(ground_truth) == len(prediction_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_with_sorted_probabilities(prediction_table,\n",
    "                                         get_highest_probability,\n",
    "                                         label,\n",
    "                                         number_of_items,\n",
    "                                         only_false_predictions=False):\n",
    "    sorted_prediction_table = [(k, prediction_table[k])\n",
    "                               for k in sorted(prediction_table,\n",
    "                                               key=prediction_table.get,\n",
    "                                               reverse=get_highest_probability)\n",
    "                               ]\n",
    "    result = []\n",
    "    for index, key in enumerate(sorted_prediction_table):\n",
    "        image_index, [probability, predicted_index, gt] = key\n",
    "        if predicted_index == label:\n",
    "            if only_false_predictions == True:\n",
    "                if predicted_index != gt:\n",
    "                    result.append(\n",
    "                        [image_index, [probability, predicted_index, gt]])\n",
    "            else:\n",
    "                result.append(\n",
    "                    [image_index, [probability, predicted_index, gt]])\n",
    "    return result[:number_of_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(filenames, distances, message):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        images.append(mpimg.imread(filename))\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    columns = 5\n",
    "    for i, image in enumerate(images):\n",
    "        ax = plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "        ax.set_title(\"\\n\\n\" + filenames[i].split(\"/\")[-1] + \"\\n\" +\n",
    "                     \"\\nProbability: \" +\n",
    "                     str(float(\"{0:.2f}\".format(distances[i]))))\n",
    "        plt.suptitle(message, fontsize=20, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "        \n",
    "def display(sorted_indices, message):\n",
    "    similar_image_paths = []\n",
    "    distances = []\n",
    "    for name, value in sorted_indices:\n",
    "        [probability, predicted_index, gt] = value\n",
    "        similar_image_paths.append(VALIDATION_DATA_DIR + filenames[name])\n",
    "        distances.append(probability)\n",
    "    plot_images(similar_image_paths, distances, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
