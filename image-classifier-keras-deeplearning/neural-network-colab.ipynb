{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IS_COLAB_ENV = True\n",
    "except:\n",
    "  IS_COLAB_ENV = False\n",
    "  print(\"Please execute the non-Colab version of this notebook.\")\n",
    "IS_COLAB_ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install tensorflow==2.0.0\n",
    "!pip install tf-explain==0.1.0\n",
    "!pip install -U pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://i.imgur.com/7mK8VHe.png --output dog.jpg\n",
    "!curl https://i.imgur.com/PdLZbpj.png --output cat.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import get_file\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "CLASS_INDEX = None\n",
    "CLASS_INDEX_PATH = 'imagenet_class_index.json'\n",
    "\n",
    "# Note: decode_predictions(preds, top) is originally a keras function.\n",
    "# We have modified it here so that it returns the index of the class label along with the predictions.\n",
    "# The results are assimilated based on the assumption that there is only one top 1% prediction.\n",
    "\n",
    "def decode_predictions_modified(preds, top=1):\n",
    "    global CLASS_INDEX\n",
    "    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n",
    "        raise ValueError(\n",
    "            '`decode_predictions` expects ' 'a batch of predictions ''(i.e. a 2D array of shape (samples, 1000)). ' 'Found array with shape: ' + str(preds.shape))\n",
    "    if CLASS_INDEX is None:\n",
    "        CLASS_INDEX = json.load(open(CLASS_INDEX_PATH))\n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        for i in top_indices:\n",
    "            results = [i, tuple(CLASS_INDEX[str(i)]), (pred[i],)]\n",
    "    return results\n",
    "\n",
    "# Function that takes an image and model and produces the predictions\n",
    "\n",
    "def get_predictions(img, model):\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    return decode_predictions_modified(preds, top=1)\n",
    "\n",
    "# NOTE: These two functions are taken from Shao-Chuan Wang <shaochuan.wang AT gmail.com> \n",
    "# as per the copyright on http://code.activestate.com/recipes/577591-conversion-of-pil-image-and-numpy-array/\n",
    "\n",
    "\"\"\"\n",
    "   Copyright 2011 Shao-Chuan Wang <shaochuan.wang AT gmail.com>\n",
    "\n",
    "    Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "    of this software and associated documentation files (the \"Software\"), to deal\n",
    "    in the Software without restriction, including without limitation the rights\n",
    "    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "    copies of the Software, and to permit persons to whom the Software is\n",
    "    furnished to do so, subject to the following conditions:\n",
    "\n",
    "    The above copyright notice and this permission notice shall be included in\n",
    "    all copies or substantial portions of the Software.\n",
    "\n",
    "    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "    THE SOFTWARE.\n",
    "\"\"\"\n",
    "# Modified from the original format to take only the array as input and calculate the size on the fly\n",
    "def array_to_PIL(arr):\n",
    "    mode = 'RGBA'\n",
    "    # Use only the height and width for further processing\n",
    "    size = (arr.shape[0], arr.shape[1])  # (224,224)\n",
    "    arr = arr.reshape(arr.shape[0]*arr.shape[1], arr.shape[2])\n",
    "    if len(arr[0]) == 3:\n",
    "        arr = np.c_[arr, 255*np.ones((len(arr), 1), np.uint8)]\n",
    "    return Image.frombuffer(mode, size, arr.tostring(), 'raw', mode, 0, 1)\n",
    "\n",
    "# Function that puts text based prediction and class name on top of the image\n",
    "def overlay_prediction_on_image(img, prediction_class, prediction_probability, width, height):\n",
    "    img = img.resize((width, height), Image.ANTIALIAS)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    l = len(prediction_class)\n",
    "    # Place a black rectangle to provide a background for the text\n",
    "    # The size of the rectangle should change with respect to the image\n",
    "    draw.rectangle([int(width*0.05), int(width*0.05),\n",
    "                    int(width*0.5), int(width*0.11)], fill=(0, 0, 0))\n",
    "    draw.text((int(width*0.06), int(width*0.06)), '{0:.0f}'.format(\n",
    "        prediction_probability) + \"% \" + prediction_class, fill=(255, 255, 255))\n",
    "    return img\n",
    "\n",
    "# Based on StackOverflow code by user DTing\n",
    "# https://stackoverflow.com/questions/30227466/combine-several-images-horizontally-with-python\n",
    "# Join image\n",
    "def join_images(img1, img2):\n",
    "    widths, heights = zip(*(i.size for i in [img1, img2]))\n",
    "    total_width = sum(widths)\n",
    "    max_height = max(heights)\n",
    "    new_img = Image.new('RGB', (total_width, max_height))\n",
    "    x_offset = 0\n",
    "    for img in [img1, img2]:\n",
    "        new_img.paste(img, (x_offset, 0))\n",
    "        x_offset += img.size[0]\n",
    "    return new_img\n",
    "\n",
    "def process_image(image_path, output_path):\n",
    "    model = VGG16(weights='imagenet', include_top=True, input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "    explainer = GradCAM()\n",
    "\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    data = ([img], None)\n",
    "\n",
    "    original_image = Image.open(image_path)\n",
    "    width = int(original_image.size[0]/4)\n",
    "    height = int(original_image.size[1]/4)\n",
    "    original_image.thumbnail((width, height), Image.ANTIALIAS)\n",
    "\n",
    "    class_index, class_name, prob_value = get_predictions(img, model)\n",
    "    # Heatmap\n",
    "    heatmap = explainer.explain(data, model, \"block5_conv3\", class_index)\n",
    "\n",
    "    # overlay the text prediction on the heatmap overlay\n",
    "    heatmap_with_prediction_overlayed = overlay_prediction_on_image(\n",
    "        array_to_PIL(heatmap), class_name[-1], prob_value[0] * 100, width, height)\n",
    "\n",
    "    # place the images side by side\n",
    "    joined_image = join_images(\n",
    "        original_image, heatmap_with_prediction_overlayed)\n",
    "    joined_image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_image(\"dog.jpg\", \"dog_output.jpg\")\n",
    "process_image(\"cat.jpg\", \"cat_output.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open('dog_output.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap\n",
    "!python visualization.py --process image --path ../../sample-images/dog.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of video\n",
    "!mkdir kitchen\n",
    "!ffmpeg -i kitchen-input.mov -vf fps=25 data/kitchen/thumb%04d.jpg -hide_banner\n",
    "!python visualization.py --process video --path data/kitchen/\n",
    "!ffmpeg -framerate 25 -i data/kitchen_output/result-%04d.jpg kitchen-output.mp4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
